{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Astroinformática II - Aula 15.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucianosilvacraam/astro/blob/master/Astroinform%C3%A1tica_II_Aula_15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VN2_d0hePb0h",
        "colab_type": "text"
      },
      "source": [
        "Aula 15: Máquinas Regressoras para aprender o conceito de RedSfhit de Galáxias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GXsPnNvRQn4",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yg82l8viPTv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install astroml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zz8XlM1RZge",
        "colab_type": "text"
      },
      "source": [
        "Regressão com Árvores de Decisão"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StBHEzVePwK2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Author: Jake VanderPlas\n",
        "# License: BSD\n",
        "#   The figure produced by this code is published in the textbook\n",
        "#   \"Statistics, Data Mining, and Machine Learning in Astronomy\" (2013)\n",
        "#   For more information, see http://astroML.github.com\n",
        "#   To report a bug or issue, use the following forum:\n",
        "#    https://groups.google.com/forum/#!forum/astroml-general\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from astroML.datasets import fetch_sdss_specgals\n",
        "\n",
        "#----------------------------------------------------------------------\n",
        "# This function adjusts matplotlib settings for a uniform feel in the textbook.\n",
        "# Note that with usetex=True, fonts are rendered with LaTeX.  This may\n",
        "# result in an error if LaTeX is not installed on your system.  In that case,\n",
        "# you can set usetex to False.\n",
        "if \"setup_text_plots\" not in globals():\n",
        "    from astroML.plotting import setup_text_plots\n",
        "setup_text_plots(fontsize=8, usetex=False)\n",
        "\n",
        "#------------------------------------------------------------\n",
        "# Fetch data and prepare it for the computation\n",
        "data = fetch_sdss_specgals()\n",
        "\n",
        "# put magnitudes in a matrix\n",
        "mag = np.vstack([data['modelMag_%s' % f] for f in 'ugriz']).T\n",
        "z = data['z']\n",
        "\n",
        "# train on ~60,000 points\n",
        "mag_train = mag[::10]\n",
        "z_train = z[::10]\n",
        "\n",
        "# test on ~6,000 separate points\n",
        "mag_test = mag[1::100]\n",
        "z_test = z[1::100]\n",
        "\n",
        "#------------------------------------------------------------\n",
        "# Compute the cross-validation scores for several tree depths\n",
        "depth = np.arange(1, 21)\n",
        "rms_test = np.zeros(len(depth))\n",
        "rms_train = np.zeros(len(depth))\n",
        "i_best = 0\n",
        "z_fit_best = None\n",
        "\n",
        "for i, d in enumerate(depth):\n",
        "    clf = DecisionTreeRegressor(max_depth=d, random_state=0)\n",
        "    clf.fit(mag_train, z_train)\n",
        "\n",
        "    z_fit_train = clf.predict(mag_train)\n",
        "    z_fit = clf.predict(mag_test)\n",
        "    rms_train[i] = np.mean(np.sqrt((z_fit_train - z_train) ** 2))\n",
        "    rms_test[i] = np.mean(np.sqrt((z_fit - z_test) ** 2))\n",
        "\n",
        "    if rms_test[i] <= rms_test[i_best]:\n",
        "        i_best = i\n",
        "        z_fit_best = z_fit\n",
        "\n",
        "best_depth = depth[i_best]\n",
        "\n",
        "#------------------------------------------------------------\n",
        "# Plot the results\n",
        "fig = plt.figure(figsize=(5, 2.5))\n",
        "fig.subplots_adjust(wspace=0.25,\n",
        "                    left=0.1, right=0.95,\n",
        "                    bottom=0.15, top=0.9)\n",
        "\n",
        "# first panel: cross-validation\n",
        "ax = fig.add_subplot(121)\n",
        "ax.plot(depth, rms_test, '-k', label='cross-validation')\n",
        "ax.plot(depth, rms_train, '--k', label='training set')\n",
        "ax.set_xlabel('depth of tree')\n",
        "ax.set_ylabel('rms error')\n",
        "ax.yaxis.set_major_locator(plt.MultipleLocator(0.01))\n",
        "ax.set_xlim(0, 21)\n",
        "ax.set_ylim(0.009,  0.04)\n",
        "ax.legend(loc=1)\n",
        "\n",
        "# second panel: best-fit results\n",
        "ax = fig.add_subplot(122)\n",
        "edges = np.linspace(z_test.min(), z_test.max(), 101)\n",
        "H, zs_bins, zp_bins = np.histogram2d(z_test, z_fit_best, bins=edges)\n",
        "ax.imshow(H.T, origin='lower', interpolation='nearest', aspect='auto', \n",
        "           extent=[zs_bins[0], zs_bins[-1], zs_bins[0], zs_bins[-1]],\n",
        "           cmap=plt.cm.binary)\n",
        "ax.plot([-0.1, 0.4], [-0.1, 0.4], ':k')\n",
        "ax.text(0.04, 0.96, \"depth = %i\\nrms = %.3f\" % (best_depth, rms_test[i_best]),\n",
        "        ha='left', va='top', transform=ax.transAxes)\n",
        "ax.set_xlabel(r'$z_{\\rm true}$')\n",
        "ax.set_ylabel(r'$z_{\\rm fit}$')\n",
        "\n",
        "ax.set_xlim(-0.02, 0.4001)\n",
        "ax.set_ylim(-0.02, 0.4001)\n",
        "ax.xaxis.set_major_locator(plt.MultipleLocator(0.1))\n",
        "ax.yaxis.set_major_locator(plt.MultipleLocator(0.1))\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWi4bFY8ReQH",
        "colab_type": "text"
      },
      "source": [
        "Regressão com Florestas Aleatórias\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDUtaqiKRj97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Author: Jake VanderPlas\n",
        "# License: BSD\n",
        "#   The figure produced by this code is published in the textbook\n",
        "#   \"Statistics, Data Mining, and Machine Learning in Astronomy\" (2013)\n",
        "#   For more information, see http://astroML.github.com\n",
        "#   To report a bug or issue, use the following forum:\n",
        "#    https://groups.google.com/forum/#!forum/astroml-general\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from astroML.datasets import fetch_sdss_specgals\n",
        "from astroML.utils.decorators import pickle_results\n",
        "\n",
        "\n",
        "#----------------------------------------------------------------------\n",
        "# This function adjusts matplotlib settings for a uniform feel in the textbook.\n",
        "# Note that with usetex=True, fonts are rendered with LaTeX.  This may\n",
        "# result in an error if LaTeX is not installed on your system.  In that case,\n",
        "# you can set usetex to False.\n",
        "if \"setup_text_plots\" not in globals():\n",
        "    from astroML.plotting import setup_text_plots\n",
        "setup_text_plots(fontsize=8, usetex=False)\n",
        "\n",
        "#------------------------------------------------------------\n",
        "# Fetch and prepare the data\n",
        "data = fetch_sdss_specgals()\n",
        "\n",
        "# put magnitudes in a matrix\n",
        "mag = np.vstack([data['modelMag_%s' % f] for f in 'ugriz']).T\n",
        "z = data['z']\n",
        "\n",
        "# train on ~60,000 points\n",
        "mag_train = mag[::10]\n",
        "z_train = z[::10]\n",
        "\n",
        "# test on ~6,000 distinct points\n",
        "mag_test = mag[1::100]\n",
        "z_test = z[1::100]\n",
        "\n",
        "\n",
        "#------------------------------------------------------------\n",
        "# Compute the results\n",
        "#  This is a long computation, so we'll save the results to a pickle.\n",
        "@pickle_results('photoz_boosting.pkl')\n",
        "def compute_photoz_forest(N_boosts):\n",
        "    rms_test = np.zeros(len(N_boosts))\n",
        "    rms_train = np.zeros(len(N_boosts))\n",
        "    i_best = 0\n",
        "    z_fit_best = None\n",
        "\n",
        "    for i, Nb in enumerate(N_boosts):\n",
        "        try:\n",
        "            # older versions of scikit-learn\n",
        "            clf = GradientBoostingRegressor(n_estimators=Nb, learn_rate=0.1,\n",
        "                                            max_depth=3, random_state=0)\n",
        "        except TypeError:\n",
        "            clf = GradientBoostingRegressor(n_estimators=Nb, learning_rate=0.1,\n",
        "                                            max_depth=3, random_state=0)\n",
        "        clf.fit(mag_train, z_train)\n",
        "\n",
        "        z_fit_train = clf.predict(mag_train)\n",
        "        z_fit = clf.predict(mag_test)\n",
        "        rms_train[i] = np.mean(np.sqrt((z_fit_train - z_train) ** 2))\n",
        "        rms_test[i] = np.mean(np.sqrt((z_fit - z_test) ** 2))\n",
        "\n",
        "        if rms_test[i] <= rms_test[i_best]:\n",
        "            i_best = i\n",
        "            z_fit_best = z_fit\n",
        "\n",
        "    return rms_test, rms_train, i_best, z_fit_best\n",
        "\n",
        "N_boosts = (10, 100, 200, 300, 400, 500)\n",
        "rms_test, rms_train, i_best, z_fit_best = compute_photoz_forest(N_boosts)\n",
        "best_N = N_boosts[i_best]\n",
        "\n",
        "#------------------------------------------------------------\n",
        "# Plot the results\n",
        "fig = plt.figure(figsize=(5, 2.5))\n",
        "fig.subplots_adjust(wspace=0.25,\n",
        "                    left=0.1, right=0.95,\n",
        "                    bottom=0.15, top=0.9)\n",
        "\n",
        "# left panel: plot cross-validation results\n",
        "ax = fig.add_subplot(121)\n",
        "ax.plot(N_boosts, rms_test, '-k', label='cross-validation')\n",
        "ax.plot(N_boosts, rms_train, '--k', label='training set')\n",
        "ax.legend(loc=1)\n",
        "\n",
        "ax.set_xlabel('number of boosts')\n",
        "ax.set_ylabel('rms error')\n",
        "ax.set_xlim(0, 510)\n",
        "ax.set_ylim(0.009,  0.032)\n",
        "ax.yaxis.set_major_locator(plt.MultipleLocator(0.01))\n",
        "\n",
        "ax.text(0.03, 0.03, \"Tree depth: 3\",\n",
        "        ha='left', va='bottom', transform=ax.transAxes)\n",
        "\n",
        "# right panel: plot best fit\n",
        "ax = fig.add_subplot(122)\n",
        "edges = np.linspace(z_test.min(), z_test.max(), 101)\n",
        "H, zs_bins, zp_bins = np.histogram2d(z_test, z_fit_best, bins=edges)\n",
        "ax.imshow(H.T, origin='lower', interpolation='nearest', aspect='auto', \n",
        "           extent=[zs_bins[0], zs_bins[-1], zs_bins[0], zs_bins[-1]],\n",
        "           cmap=plt.cm.binary)\n",
        "\n",
        "ax.plot([-0.1, 0.4], [-0.1, 0.4], ':k')\n",
        "ax.text(0.04, 0.96, \"N = %i\\nrms = %.3f\" % (best_N, rms_test[i_best]),\n",
        "        ha='left', va='top', transform=ax.transAxes)\n",
        "\n",
        "ax.set_xlabel(r'$z_{\\rm true}$')\n",
        "ax.set_ylabel(r'$z_{\\rm fit}$')\n",
        "\n",
        "ax.set_xlim(-0.02, 0.4001)\n",
        "ax.set_ylim(-0.02, 0.4001)\n",
        "ax.xaxis.set_major_locator(plt.MultipleLocator(0.1))\n",
        "ax.yaxis.set_major_locator(plt.MultipleLocator(0.1))\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}